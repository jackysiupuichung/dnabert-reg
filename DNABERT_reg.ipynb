{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DNABERT_reg.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyM8MsetTX4/jP9JYWL8DUsU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XaL4dzTiV5cv","executionInfo":{"status":"ok","timestamp":1642087169514,"user_tz":0,"elapsed":19038,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"3841198d-2297-431c-9f72-6d5988a54567"},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"ZlGhaGHY1WV5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642087176151,"user_tz":0,"elapsed":6701,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"eb1882e5-9cd6-4e19-8365-a211b7050119"},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 30.9 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 56.0 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 7.5 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 81.0 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 97.6 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0\n"]}]},{"cell_type":"code","metadata":{"id":"wmQPCY8702co","executionInfo":{"status":"ok","timestamp":1642087183358,"user_tz":0,"elapsed":7256,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"source":["from transformers import BertForSequenceClassification, BertTokenizer, BertConfig,AdamW , get_linear_schedule_with_warmup\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import r2_score\n","import itertools\n","import pandas as pd\n","import numpy as np\n","import random"],"execution_count":3,"outputs":[]},{"cell_type":"code","source":["random.seed(42)"],"metadata":{"id":"PNSXyJT83If6","executionInfo":{"status":"ok","timestamp":1642087183400,"user_tz":0,"elapsed":59,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vhfCOUX0a9H1","executionInfo":{"status":"ok","timestamp":1642087183400,"user_tz":0,"elapsed":58,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"f8749ce4-fc60-49ff-c1c8-07f2f0af4532"},"source":["cd /content/drive/MyDrive/master_thesis/inputs/"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/master_thesis/inputs\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"44M-RlFZ2-yS","executionInfo":{"status":"ok","timestamp":1642087184715,"user_tz":0,"elapsed":1367,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"14237553-cf01-4290-a481-026310eddd43"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["ENCFF292FVY.tsv  ENCFF910TAZ.tsv  \u001b[0m\u001b[01;34mhg38_msxTm_ENCFF292FVY\u001b[0m/  hg38_msxTm.txt\n","ENCFF694PZC.tsv  \u001b[01;34mfind_motifs\u001b[0m/     \u001b[01;34mhg38_msxTm_ENCFF910TAZ\u001b[0m/\n"]}]},{"cell_type":"code","source":["input_csv = \"hg38_msxTm_ENCFF910TAZ/hg38_msxTm_ENCFF910TAZ.csv\""],"metadata":{"id":"HSl6gMSTva_d","executionInfo":{"status":"ok","timestamp":1642087185007,"user_tz":0,"elapsed":344,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UDl0v5ezarma"},"source":["Import input that was parsed using inputparser.ipynb"]},{"cell_type":"code","metadata":{"id":"H-xoqJnD426N","executionInfo":{"status":"ok","timestamp":1642087185265,"user_tz":0,"elapsed":263,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"source":["final_matrix = pd.read_csv(input_csv)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["choose pretrained model from 3 to 6 mer (!!!change seq2kmer k)"],"metadata":{"id":"Yjffz4Jp_TAy"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"drh-uppF0avG","executionInfo":{"status":"ok","timestamp":1642087185609,"user_tz":0,"elapsed":348,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"ced3faf5-1821-461e-ef65-652e828f252b"},"source":["cd /content/drive/MyDrive/master_thesis/models/4-new-12w-0/"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/master_thesis/models/4-new-12w-0\n"]}]},{"cell_type":"code","metadata":{"id":"1izCagm9gYOL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642087185610,"user_tz":0,"elapsed":53,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"f4bad357-5835-4436-966a-8d9bebc8e393"},"source":["import torch\n","if torch.cuda.is_available():       \n","    device = torch.device(\"cuda\")\n","    print(\"Using GPU.\")\n","else:\n","    print(\"No GPU available, using the CPU instead.\")\n","    device = torch.device(\"cpu\")"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Using GPU.\n"]}]},{"cell_type":"markdown","metadata":{"id":"5eVuxQiSH8RY"},"source":["Parse sample data into pytorch object to pass through BERT trainer https://huggingface.co/transformers/custom_datasets.html https://huggingface.co/transformers/main_classes/trainer.html#transformers.Trainer\n","https://huggingface.co/transformers/custom_datasets.html"]},{"cell_type":"code","metadata":{"id":"3VU2UVJTL-Fp","executionInfo":{"status":"ok","timestamp":1642087186089,"user_tz":0,"elapsed":529,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"source":["DNABERT_Tokenizer = BertTokenizer(vocab_file = \"vocab.txt\", config = \"tokenizer_config.json\")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"LIITxOb9qvtB","executionInfo":{"status":"ok","timestamp":1642087186090,"user_tz":0,"elapsed":74,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"source":["def seq2kmer(seq, k = 4):\n","    \"\"\"\n","    Function provided by Ji et al. (https://github.com/jerryji1993/DNABERT)\n","    Will convert given sequence into kmer.\n","    \"\"\"\n","    kmer = [seq[x:x+k] for x in range(len(seq)+1-k)]\n","    kmers = \" \".join(kmer)\n","    return kmer"],"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def kmer2seq(kmers):\n","    \"\"\"\n","    Convert kmers to original sequence\n","    \n","    Arguments:\n","    kmers -- str, kmers separated by space.\n","    \n","    Returns:\n","    seq -- str, original sequence.\n","    \"\"\"\n","    kmers_list = kmers.split(\" \")\n","    bases = [kmer[0] for kmer in kmers_list[0:-1]]\n","    bases.append(kmers_list[-1])\n","    seq = \"\".join(bases)\n","    assert len(seq) == len(kmers_list) + len(kmers_list[0]) - 1\n","    return seq"],"metadata":{"id":"p1NaV2OZcJD6","executionInfo":{"status":"ok","timestamp":1642087186090,"user_tz":0,"elapsed":73,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"3y2EsgVi1El8","executionInfo":{"status":"ok","timestamp":1642087186090,"user_tz":0,"elapsed":73,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"source":["def tokenize(seq_kmers, labels):\n","  input_ids = []\n","  attention_masks = []\n","\n","  for sent in seq_kmers:\n","      encoded_dict = DNABERT_Tokenizer.encode_plus(\n","                          sent,                      # Sentence to encode.\n","                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                          # Pad & truncate all sentences. (does not apply for our data since the lengths are all the same)\n","                          max_length = 297,\n","                          pad_to_max_length = True,\n","                          return_attention_mask = True,   # Construct attention masks.\n","                          return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","      \n","      # Add the encoded sentence to the list.    \n","      input_ids.append(encoded_dict['input_ids'])\n","      \n","      # And its attention mask (simply differentiates padding from non-padding).\n","      attention_masks.append(encoded_dict['attention_mask'])\n","\n","  input_ids = torch.cat(input_ids, dim=0)\n","  attention_masks = torch.cat(attention_masks, dim=0)\n","  labels = torch.tensor(labels)\n","\n","  # Combine the training inputs into a TensorDataset.\n","  dataset = TensorDataset(input_ids, attention_masks, labels)\n","  return dataset"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yBq3iQHGBn-w","executionInfo":{"status":"ok","timestamp":1642087187061,"user_tz":0,"elapsed":1043,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"92142f5a-d816-4fd2-ae51-2e2b25ccfa06"},"source":["seq_kmers = list(map(seq2kmer, final_matrix[\"Sequence\"].tolist()))\n","dataset = tokenize(seq_kmers, final_matrix[\"logTPM\"].tolist())"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","metadata":{"id":"uKFhAkyz2mch","executionInfo":{"status":"ok","timestamp":1642087187061,"user_tz":0,"elapsed":65,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"source":["train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=1)\n","train_dataset, val_dataset = train_test_split(train_dataset, test_size=0.25, random_state=1)"],"execution_count":16,"outputs":[]},{"cell_type":"code","source":["print(\"dataset size = \", len(dataset))\n","print(\"train_dataset size = \", len(train_dataset))\n","print(\"val_dataset size = \", len(val_dataset))\n","print(\"test_dataset size = \", len(test_dataset))\n"],"metadata":{"id":"7peFnYpXQZme","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642087187062,"user_tz":0,"elapsed":65,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"7a22e27b-7b11-4de8-c52b-9957d439f255"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["dataset size =  1919\n","train_dataset size =  1151\n","val_dataset size =  384\n","test_dataset size =  384\n"]}]},{"cell_type":"code","metadata":{"id":"ZcKtJz882Da-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642087192151,"user_tz":0,"elapsed":5149,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"e52e96b2-b483-4a64-fd30-76c0f9c2fc32"},"source":["model_config_path = \"./config.json\"\n","model_config =BertConfig.from_pretrained(model_config_path, num_labels = 1)\n","model_weight_path = \"./pytorch_model.bin\"\n","dnabert = BertForSequenceClassification.from_pretrained(model_weight_path, config = model_config)"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at ./pytorch_model.bin were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./pytorch_model.bin and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","metadata":{"id":"52e5EUO3XvvX"},"source":["# Get all of the model's parameters as a list of tuples.\n","params = list(dnabert.named_parameters())\n","\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ni6lsti7F5lV"},"source":["BERT authors suggest:\n","batch sizes: 8, 16, 32, 64, 128\n","learning rates: 3e-4, 1e-4, 5e-5, 3e-5\n","\n","https://github.com/google-research/bert"]},{"cell_type":"code","metadata":{"id":"_iMYAV0Rwy8x"},"source":["batch_size = 16\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","validation_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n","\n","batch_lr = {8:3e-4, 16:1e-4, 32: 5e-5, 64: 3e-5, 128: 3e-5}\n","\n","optimizer = AdamW(dnabert.parameters(), lr=batch_lr[batch_size])\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 4\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)\n","\n","model = dnabert\n","model.to(device)                                  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-wSGAcE8xHr"},"source":["def train(model, optimizer, scheduler, epochs,       \n","          train_dataloader, validation_dataloader, device, clip_value=2):\n","    training_stats = []\n","\n","    for epoch_i in range(0, epochs):\n","        print(\"\")\n","        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","        print('Training...')\n","        total_train_loss = 0\n","        for batch in train_dataloader:\n","            input_ids = batch[0].to(device)\n","            attention_mask = batch[1].to(device)\n","            labels = batch[2].to(device)\n","            #https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch\n","            \n","            optimizer.zero_grad()\n","            model.zero_grad()\n","\n","            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","            loss = outputs[0]\n","            total_train_loss += loss.item()\n","            loss.backward()\n","            # Clip the norm of the gradients to 1.0.\n","            # This is to help prevent the \"exploding gradients\" problem.\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n","            optimizer.step()\n","            scheduler.step()\n","\n","        avg_train_loss = total_train_loss / len(train_dataloader)\n","        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","\n","        # ========================================\n","        #               Validation\n","        # ========================================\n","        # After the completion of each training epoch, measure our performance on\n","        # our validation set.\n","        \n","        print(\"\")\n","        print(\"Running Validation...\")\n","\n","        model.eval()\n","\n","        # Tracking variables \n","        total_eval_accuracy = 0\n","        total_eval_loss = 0\n","        nb_eval_steps = 0\n","\n","        # Evaluate data for one epoch\n","        for batch in validation_dataloader:\n","            b_input_ids = batch[0].to(device)\n","            b_input_mask = batch[1].to(device)\n","            b_labels = batch[2].to(device)\n","            \n","            # Tell pytorch not to bother with constructing the compute graph during\n","            # the forward pass, since this is only needed for backprop (training).\n","            with torch.no_grad():\n","                output = model(b_input_ids, \n","                                      token_type_ids=None, \n","                                      attention_mask=b_input_mask,\n","                                      labels=b_labels)\n","            \n","            loss = output[0]\n","            # Accumulate the validation loss.\n","            total_eval_loss += loss.item()\n","\n","\n","        # Calculate the average loss over all of the batches.\n","        avg_val_loss = total_eval_loss / len(validation_dataloader)\n","        \n","        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","\n","        # Record all statistics from this epoch.\n","        training_stats.append(\n","            {\n","                'epoch': epoch_i + 1,\n","                'Training Loss': avg_train_loss,\n","                'Valid. Loss': avg_val_loss,\n","            }\n","        )\n","    return model, training_stats"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fY0_L9G7gsWE","colab":{"base_uri":"https://localhost:8080/","height":478},"executionInfo":{"status":"error","timestamp":1642079860410,"user_tz":0,"elapsed":70054,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"41a7ccd6-0635-41e7-b8bd-50bbf492285e"},"source":["ft_dnabert_model, training_stats = train(model, optimizer, scheduler, epochs, \n","              train_dataloader, validation_dataloader, device, clip_value=2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n","  Average training loss: 6.48\n","\n","Running Validation...\n","  Validation Loss: 6.15\n","\n","======== Epoch 2 / 4 ========\n","Training...\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-c57f37909c2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m ft_dnabert_model, training_stats = train(model, optimizer, scheduler, epochs, \n\u001b[0;32m----> 2\u001b[0;31m               train_dataloader, validation_dataloader, device, clip_value=2)\n\u001b[0m","\u001b[0;32m<ipython-input-20-6fe75c0c7e63>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler, epochs, train_dataloader, validation_dataloader, device, clip_value)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Clip the norm of the gradients to 1.0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"Gkfq8gEuqG1s"},"source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# Display the table.\n","df_stats"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GP2TQIgN82gt"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks(list(range(1, 5)))\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zw_Bx_YE0BJC","executionInfo":{"status":"ok","timestamp":1642087499398,"user_tz":0,"elapsed":272,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e67e1c58-f7f3-4927-e08b-75cfd541b31c"},"source":["cd /content/drive/MyDrive/master_thesis/models/4-new-12w-0/ft_dnabert_model_4mer_save/"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/master_thesis/models/4-new-12w-0/ft_dnabert_model_4mer_save\n"]}]},{"cell_type":"code","metadata":{"id":"foMgBPc41OT2","executionInfo":{"status":"ok","timestamp":1642087507582,"user_tz":0,"elapsed":6484,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"source":["DNABERT_Tokenizer = BertTokenizer(vocab_file = \"vocab.txt\", config = \"tokenizer_config.json\")\n","\n","ft_model_config_path = \"./config.json\"\n","ft_model_config =BertConfig.from_pretrained(ft_model_config_path, num_labels = 1)\n","\n","ft_model_weight_path = \"./pytorch_model.bin\"\n","ft_dnabert_model = BertForSequenceClassification.from_pretrained(ft_model_weight_path, config = ft_model_config)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["Save the best performing model (4mer) in output dir"],"metadata":{"id":"D2Cnyt3asgmu"}},{"cell_type":"code","metadata":{"id":"vQRTxuNMrNL2"},"source":["import os\n","\n","# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n","\n","output_dir = './ft_dnabert_model_4mer_save/'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","model_to_save = model.module if hasattr(ft_dnabert_model, 'module') else ft_dnabert_model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","DNABERT_Tokenizer.save_pretrained(output_dir)\n","\n","# Good practice: save your training arguments together with the trained model\n","#torch.save(args, os.path.join(output_dir, 'training_args.bin'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wC0H0tUD2rKR"},"source":["Make prediction on test data"]},{"cell_type":"code","metadata":{"id":"Ax8b7hS_3hY2","executionInfo":{"status":"ok","timestamp":1642087563599,"user_tz":0,"elapsed":224,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"source":["def predict(model, test_dataset, device):\n","\n","  batch_size = 1\n","  prediction_dataloader = DataLoader(test_dataset, batch_size, shuffle=True)\n","  # Put model in evaluation mode\n","  model.eval()\n","  # Tracking variables\n","  max_seq_length = 297 #this variable is subject to change when kmer model and sequence length varies\n","  preds = None\n","  true_labels = []\n","  attention_scores = np.zeros([len(test_dataset), 12, max_seq_length, max_seq_length])\n","  sequences = []\n","  model.to(device)\n","  # ========================================\n","  #               Prediction\n","  # ========================================\n","  print(\"\")\n","  print(\"Running Prediction...\")\n","\n","  for index, batch in enumerate(prediction_dataloader):\n","      b_input_ids = batch[0].to(device)\n","      b_input_mask = batch[1].to(device)\n","      b_labels = batch[2].to(device)\n","\n","      # Telling the model not to compute or store gradients, saving memory and \n","      # speeding up prediction\n","      with torch.no_grad():\n","          # Forward pass, calculate logit predictions\n","          #b_label not required for predictions, no loss is calucalated\n","          outputs = model(b_input_ids, token_type_ids=None, \n","                          attention_mask=b_input_mask, output_attentions=True)\n","          \"\"\"\n","          attention = outputs[-1][-1]\n","          _, logits = outputs[:2]\n","\n","          preds[index*batch_size:index*batch_size+len(batch[0]),:] = logits.detach().cpu().numpy()\n","          attention_scores[index*batch_size:index*batch_size+len(batch[0]),:,:,:] = attention.cpu().numpy()\n","                # if preds is None:\n","                #     preds = logits.detach().cpu().numpy()\n","                # else:\n","                #     preds = np.concatenate((preds, logits.detach().cpu().numpy()), axis=0)\n","\n","                # if attention_scores is not None:\n","                #     attention_scores = np.concatenate((attention_scores, attention.cpu().numpy()), 0)\n","                # else:\n","                #     attention_scores = attention.cpu().numpy()\n","          \"\"\"\n","          logits = outputs[0]\n","          if preds is None:\n","              preds = logits.detach().cpu().numpy()\n","          else:\n","              preds = np.concatenate((preds, logits.detach().cpu().numpy()), axis=0)\n","          true_labels.append(b_labels)\n","          attention = outputs[-1][-1].cpu().numpy()\n","          attention_scores[index*batch_size:index*batch_size+len(batch[0]),:,:,:] = attention\n","          sequences.append(b_input_ids.cpu().tolist())\n","  \n","  sequences=np.array(sequences).squeeze()\n","\n","\n","  print(\"\")\n","  print(\"Prediction completed\")\n","\n","  return preds, true_labels, attention_scores, sequences\n"],"execution_count":21,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"EtzUU8_DFBaH"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FILe8CvZhv4J","executionInfo":{"status":"ok","timestamp":1642087587563,"user_tz":0,"elapsed":20316,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"05b80568-8561-4cb7-bcf2-9201d0a1a606"},"source":["predictions, labels, attention_scores, sequences = predict(ft_dnabert_model, test_dataset, device)"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Running Prediction...\n","\n","Prediction completed\n"]}]},{"cell_type":"code","source":["cd /content/drive/My Drive/master_thesis/inputs/find_motifs/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xYao2aLly0_r","executionInfo":{"status":"ok","timestamp":1642087601563,"user_tz":0,"elapsed":480,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"d0e76b7d-cda7-47c7-b5d4-d8a0c3073d87"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/master_thesis/inputs/find_motifs\n"]}]},{"cell_type":"code","source":["#removed probs because that is for classification\n","def summariesallhead(attention_scores, kmer = 4):\n","\n","    \"\"\"\n","    Seems like it reduced dimension from (batchsize, heads, kmer-len, kmer-len) \n","    to (batchsize, kmer-len)\n","    for here is (384, 12, 297, 297)\n","    \"\"\"\n","    scores = np.zeros([attention_scores.shape[0], attention_scores.shape[-1]])\n","\n","    for index, attention_score in enumerate(attention_scores):\n","        attn_score = []\n","        for i in range(1, attention_score.shape[-1]-kmer+2):\n","            attn_score.append(float(attention_score[:,0,i].sum()))\n","\n","        for i in range(len(attn_score)-1):\n","            if attn_score[i+1] == 0:\n","                attn_score[i] = 0\n","                break\n","\n","        # attn_score[0] = 0    \n","        counts = np.zeros([len(attn_score)+kmer-1])\n","        real_scores = np.zeros([len(attn_score)+kmer-1])\n","        for i, score in enumerate(attn_score):\n","            for j in range(kmer):\n","                counts[i+j] += 1.0\n","                real_scores[i+j] += score\n","        real_scores = real_scores / counts\n","        real_scores = real_scores / np.linalg.norm(real_scores)\n","\n","        scores[index] = real_scores\n","        \n","\n","    return scores"],"metadata":{"id":"BIjQnjxeRDXp","executionInfo":{"status":"ok","timestamp":1642087593285,"user_tz":0,"elapsed":346,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def summarieseachhead(attention_scores, head, kmer = 4):\n","\n","    \"\"\"\n","    Seems like it reduced dimension from (batchsize, heads, kmer-len, kmer-len) \n","    to (batchsize, kmer-len)\n","    for here is (384, 12, 297, 297)\n","    \"\"\"\n","    scores = np.zeros([attention_scores.shape[0], attention_scores.shape[-1]])\n","\n","    for index, attention_score in enumerate(attention_scores):\n","        attn_score = []\n","        for i in range(1, attention_score.shape[-1]-kmer+2):\n","            attn_score.append(float(attention_score[head,0,i].sum()))\n","\n","        for i in range(len(attn_score)-1):\n","            if attn_score[i+1] == 0:\n","                attn_score[i] = 0\n","                break\n","\n","        # attn_score[0] = 0    \n","        counts = np.zeros([len(attn_score)+kmer-1])\n","        real_scores = np.zeros([len(attn_score)+kmer-1])\n","        for i, score in enumerate(attn_score):\n","            for j in range(kmer):\n","                counts[i+j] += 1.0\n","                real_scores[i+j] += score\n","        real_scores = real_scores / counts\n","        real_scores = real_scores / np.linalg.norm(real_scores)\n","\n","        scores[index] = real_scores\n","        \n","\n","    return scores"],"metadata":{"id":"H4nC_f4_pD5Q","executionInfo":{"status":"ok","timestamp":1642087803137,"user_tz":0,"elapsed":208,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["def decode(tokenized_seqs):\n","    seqs = None\n","    for tokenized_seq in tokenized_seqs:\n","        seq = DNABERT_Tokenizer.decode(tokenized_seq,\n","                                        skip_special_tokens = True\n","                                        )\n","        seq = kmer2seq(seq)\n","        \n","        if seqs is None:\n","            seqs = seq\n","        else:\n","            seqs = np.hstack((seqs, seq))\n","    return seqs"],"metadata":{"id":"UC_1ojx6Zod_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sequences = np.load(\"sequences.npy\")\n","sequences_2 = decode(sequences)"],"metadata":{"id":"exLrhalXa28T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["att = np.load(\"attention_scores.npz.npy\")"],"metadata":{"id":"PfSKdS_CmOGz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["att_summary = summariesallhead(attention_scores)"],"metadata":{"id":"8atCII2Fmiaz","executionInfo":{"status":"ok","timestamp":1642087752494,"user_tz":0,"elapsed":893,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["for i in range (0, 12):\n","    name = \"att_\" + str(i)\n","    file = summarieseachhead(attention_scores, i)\n","    np.save((name + \".npy\"), file)"],"metadata":{"id":"rI0-KP3TowLz","executionInfo":{"status":"ok","timestamp":1642087827190,"user_tz":0,"elapsed":8908,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["att_0 = summarieseachhead(attention_scores, 0)\n","att_1 = summarieseachhead(attention_scores, 1)\n","\n","np.array_equal(att_0, att_1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-kuM4iWPmycS","executionInfo":{"status":"ok","timestamp":1642087630182,"user_tz":0,"elapsed":1705,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"137d6eb8-896a-488b-e337-a53574a8bd37"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["np.save(\"positives_seq.npy\", sequences_2) #save positive sequences in seq format\n","np.save(\"attention_scores_2d.npy\", att_summary) #save attention_scores for positive sequences in (batchsize, no.kmer)"],"metadata":{"id":"9kk0Ce8JSYBk","executionInfo":{"status":"ok","timestamp":1642087763539,"user_tz":0,"elapsed":219,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-79xOnCS53MF"},"source":["Interpret prediction vs true label\n","\n","https://stats.stackexchange.com/questions/131267/how-to-interpret-error-measures"]},{"cell_type":"code","metadata":{"id":"2XFXTBrQ7faB"},"source":["def unlist(predictions, true_labels):\n","    predictions = (list(itertools.chain(*predictions)))\n","    predictions = (list(itertools.chain(*predictions)))\n","    true_labels = [label.tolist() for label in true_labels]\n","    true_labels = (list(itertools.chain(*true_labels)))\n","    return predictions, true_labels\n","\n","def measurement_metric(predictions, true_labels, measurement):\n","    metric = measurement(true_labels, predictions)               \n","    return metric"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i5FV6K7F-sUj"},"source":["pred, lab = unlist(predictions, labels)\n","mse = measurement_metric(pred, lab, mean_squared_error)\n","r2 = measurement_metric(pred, lab, r2_score)\n","print(mse, r2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10,10))\n","plt.scatter(lab, pred, c='crimson')\n","#plt.yscale('log')\n","#plt.xscale('log')\n","\n","p1 = max(max(pred), max(lab))\n","p2 = min(min(pred), min(lab))\n","plt.plot([p1, p2], [p1, p2], 'b-')\n","plt.xlabel('True Values', fontsize=15)\n","plt.ylabel('Predictions', fontsize=15)\n","plt.axis('equal')\n","plt.show()"],"metadata":{"id":"gc9RjbR94vHr"},"execution_count":null,"outputs":[]}]}