{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DNABERT_reg_CNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMAO12PA0rIAGX8UpWxjVEZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0HRAEH95hsJ7","executionInfo":{"status":"ok","timestamp":1638810248874,"user_tz":0,"elapsed":20669,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"bd88dd84-9149-453d-d44e-c71ba505d804"},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b19bK2Uwro2-","executionInfo":{"status":"ok","timestamp":1638810256556,"user_tz":0,"elapsed":7757,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"f03c4b6f-b4c8-4d66-98c8-11b4a2eb8ed7"},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 4.8 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 50.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 38.3 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 468 kB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 37.2 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n"]}]},{"cell_type":"code","metadata":{"id":"wmQPCY8702co","executionInfo":{"status":"ok","timestamp":1638810265289,"user_tz":0,"elapsed":8784,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"source":["from transformers import BertForSequenceClassification, BertTokenizer, BertConfig,AdamW , get_linear_schedule_with_warmup\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import r2_score\n","import itertools\n","import pandas as pd"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vcJioQVrhZfe","executionInfo":{"status":"ok","timestamp":1638810265289,"user_tz":0,"elapsed":67,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"282df9e9-328d-4b6c-e494-fb8f41fb3b17"},"source":["cd /content/drive/MyDrive/master_thesis/notebooks/"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/master_thesis/notebooks\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZSuQF-oh5qs","executionInfo":{"status":"ok","timestamp":1638810265775,"user_tz":0,"elapsed":548,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"39f82211-6a21-41ad-9283-4575990080a9"},"source":["ls"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["DNABERT_reg_CNN.ipynb  DNABERT_reg.ipynb  inputparser.ipynb\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vhfCOUX0a9H1","executionInfo":{"status":"ok","timestamp":1638810265996,"user_tz":0,"elapsed":276,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"959428d7-5b97-4000-e295-1a3b7ddbc147"},"source":["cd /content/drive/MyDrive/master_thesis/inputs/"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/master_thesis/inputs\n"]}]},{"cell_type":"code","metadata":{"id":"H-xoqJnD426N","executionInfo":{"status":"ok","timestamp":1638810266244,"user_tz":0,"elapsed":250,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"source":["final_matrix = pd.read_csv(\"hg38_msxTm_ENCFF910TAZ.csv\")"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"drh-uppF0avG","executionInfo":{"status":"ok","timestamp":1638810266494,"user_tz":0,"elapsed":252,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"90c95e32-51de-4912-abae-c6864bbd430d"},"source":["cd /content/drive/MyDrive/master_thesis/models/6-new-12w-0/"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/master_thesis/models/6-new-12w-0\n"]}]},{"cell_type":"code","metadata":{"id":"1izCagm9gYOL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638810266717,"user_tz":0,"elapsed":60,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"b7c25455-6309-43c5-9644-bb6b3aba9870"},"source":["import torch\n","if torch.cuda.is_available():       \n","    device = torch.device(\"cuda\")\n","    print(\"Using GPU.\")\n","else:\n","    print(\"No GPU available, using the CPU instead.\")\n","    device = torch.device(\"cpu\")"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Using GPU.\n"]}]},{"cell_type":"code","metadata":{"id":"3VU2UVJTL-Fp","executionInfo":{"status":"ok","timestamp":1638810267186,"user_tz":0,"elapsed":523,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"source":["DNABERT_Tokenizer = BertTokenizer(vocab_file = \"vocab.txt\", config = \"tokenizer_config.json\")"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"LIITxOb9qvtB","executionInfo":{"status":"ok","timestamp":1638810267231,"user_tz":0,"elapsed":59,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"source":["def seq2kmer(seq, k = 6):\n","    \"\"\"\n","    Function provided by Ji et al. (https://github.com/jerryji1993/DNABERT)\n","    Will convert given sequence into kmer.\n","    \"\"\"\n","    kmer = [seq[x:x+k] for x in range(len(seq)+1-k)]\n","    kmers = \" \".join(kmer)\n","    return kmer"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"3y2EsgVi1El8","executionInfo":{"status":"ok","timestamp":1638810267232,"user_tz":0,"elapsed":59,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"source":["def tokenize(seq_kmers, labels):\n","  input_ids = []\n","  attention_masks = []\n","\n","  for sent in seq_kmers:\n","      encoded_dict = DNABERT_Tokenizer.encode_plus(\n","                          sent,                      # Sentence to encode.\n","                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                          # Pad & truncate all sentences. (does not apply for our data since the lengths are all the same)\n","                          max_length = 297,\n","                          pad_to_max_length = True,\n","                          return_attention_mask = True,   # Construct attention masks.\n","                          return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","      \n","      # Add the encoded sentence to the list.    \n","      input_ids.append(encoded_dict['input_ids'])\n","      \n","      # And its attention mask (simply differentiates padding from non-padding).\n","      attention_masks.append(encoded_dict['attention_mask'])\n","\n","  input_ids = torch.cat(input_ids, dim=0)\n","  attention_masks = torch.cat(attention_masks, dim=0)\n","  labels = torch.tensor(labels)\n","\n","  # Combine the training inputs into a TensorDataset.\n","  dataset = TensorDataset(input_ids, attention_masks, labels)\n","  return dataset"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yBq3iQHGBn-w","executionInfo":{"status":"ok","timestamp":1638810268586,"user_tz":0,"elapsed":1412,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"be9b8336-dba2-4d81-8dcb-1c5aebf57409"},"source":["seq_kmers = list(map(seq2kmer, final_matrix[\"Sequence\"].tolist()))\n","dataset = tokenize(seq_kmers, final_matrix[\"logTPM\"].tolist())"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","metadata":{"id":"uKFhAkyz2mch","executionInfo":{"status":"ok","timestamp":1638810268587,"user_tz":0,"elapsed":4,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"source":["train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=1)\n","train_dataset, val_dataset = train_test_split(dataset, test_size=0.25, random_state=1)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"BryTqjo4NqvO","executionInfo":{"status":"ok","timestamp":1638810268824,"user_tz":0,"elapsed":240,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"source":["model_config_path = \"/content/drive/MyDrive/master_thesis/models/6-new-12w-0/config.json\"\n","model_config =BertConfig.from_pretrained(model_config_path, num_labels = 1)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZcKtJz882Da-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638812923883,"user_tz":0,"elapsed":1498,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"abdf33ce-1c0c-43ef-c6c0-81ab558c550c"},"source":["model_weight_path = \"/content/drive/MyDrive/master_thesis/models/6-new-12w-0/pytorch_model.bin\"\n","#this load the pre-trained model WITHOUT the linear layer from BertForSequenceClassification\n","dnabert_CNN = BertForSequenceClassification.from_pretrained(model_weight_path, config = model_config).base_model"],"execution_count":61,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/master_thesis/models/6-new-12w-0/pytorch_model.bin were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/master_thesis/models/6-new-12w-0/pytorch_model.bin and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","metadata":{"id":"9PzRSxbziL72","executionInfo":{"status":"ok","timestamp":1638812914977,"user_tz":0,"elapsed":280,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"source":["class CNN_classifier(nn.Module):\n","    def __init__(self, num_labels = 1):\n","\n","        self.conv_block1 = nn.Sequential(\n","            nn.Conv1d(768, FILTERS, kernel_size=3,stride=1),\n","            nn.BatchNorm1d(FILTERS),\n","            nn.ReLU(),\n","            nn.MaxPool1d(2)\n","        )\n","        self.conv_block2 = nn.Sequential(\n","            nn.Conv1d(FILTERS, FILTERS, kernel_size=3,stride=1),\n","            nn.BatchNorm1d(FILTERS),\n","            nn.ReLU(),\n","            nn.MaxPool1d(2)\n","        )\n","        self.dense1 = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(FILTERS*10, FILTERS)\n","        )\n","        self.dense2 = nn.Sequential(\n","            nn.Linear(FILTERS, FILTERS)\n","        )\n","        self.output = nn.Linear(FILTERS, num_labels)\n","\n","    def forward(self, outputs):\n","\n","        pooled_output = outputs[1]\n","\n","        pooled_output = self.dropout(pooled_output)\n","        pooled_output = self.conv_block1(pooled_output.unsqueeze(1))\n","        pooled_output = self.conv_block2(pooled_output)\n","        pooled_output = self.conv_block2(pooled_output)\n","\n","        pooled_output = self.dense1(pooled_output)\n","        pooled_output = self.dense2(pooled_output)\n","        \n","        logits = self.output(pooled_output)\n","\n","        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n","\n","        return outputs"],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"id":"VS8Jvw0TuwDD","executionInfo":{"status":"ok","timestamp":1638812928924,"user_tz":0,"elapsed":202,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}}},"source":["dnabert_CNN.classifier = CNN_classifier"],"execution_count":62,"outputs":[]},{"cell_type":"code","metadata":{"id":"52e5EUO3XvvX"},"source":["vars(dnabert_CNN)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q9huYQ89Astu"},"source":["batch_size = 16\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","validation_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n","prediction_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"clG6SX2lHNR8"},"source":["batch_lr = {8:3e-4, 16:1e-4, 32: 5e-5, 64: 3e-5, 128: 3e-5}\n","\n","optimizer = AdamW(dnabert.parameters(), lr=batch_lr[batch_size])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_iMYAV0Rwy8x"},"source":["# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 4\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)\n","                                            "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGfTVED_mP1i","executionInfo":{"status":"ok","timestamp":1638805813461,"user_tz":0,"elapsed":11934,"user":{"displayName":"Jacky Siu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18114207530306187606"}},"outputId":"c45f748a-cc55-42a1-ca7f-e2d90e6f9236"},"source":["model = dnabert\n","model.to(device)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(4101, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"H-wSGAcE8xHr"},"source":["def train(model, optimizer, scheduler, epochs,       \n","          train_dataloader, validation_dataloader, device, clip_value=2):\n","    training_stats = []\n","\n","    for epoch_i in range(0, epochs):\n","        print(\"\")\n","        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","        print('Training...')\n","        total_train_loss = 0\n","        for batch in train_dataloader:\n","            input_ids = batch[0].to(device)\n","            attention_mask = batch[1].to(device)\n","            labels = batch[2].to(device)\n","            #https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch\n","            \n","            optimizer.zero_grad()\n","            model.zero_grad()\n","\n","            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","            loss = outputs[0]\n","            total_train_loss += loss.item()\n","            loss.backward()\n","            # Clip the norm of the gradients to 1.0.\n","            # This is to help prevent the \"exploding gradients\" problem.\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n","            optimizer.step()\n","            scheduler.step()\n","\n","        avg_train_loss = total_train_loss / len(train_dataloader)\n","        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","\n","        # ========================================\n","        #               Validation\n","        # ========================================\n","        # After the completion of each training epoch, measure our performance on\n","        # our validation set.\n","        \n","        print(\"\")\n","        print(\"Running Validation...\")\n","\n","        model.eval()\n","\n","        # Tracking variables \n","        total_eval_accuracy = 0\n","        total_eval_loss = 0\n","        nb_eval_steps = 0\n","\n","        # Evaluate data for one epoch\n","        for batch in validation_dataloader:\n","            b_input_ids = batch[0].to(device)\n","            b_input_mask = batch[1].to(device)\n","            b_labels = batch[2].to(device)\n","            \n","            # Tell pytorch not to bother with constructing the compute graph during\n","            # the forward pass, since this is only needed for backprop (training).\n","            with torch.no_grad():\n","                output = model(b_input_ids, \n","                                      token_type_ids=None, \n","                                      attention_mask=b_input_mask,\n","                                      labels=b_labels)\n","            \n","            loss = output[0]\n","            # Accumulate the validation loss.\n","            total_eval_loss += loss.item()\n","\n","\n","        # Calculate the average loss over all of the batches.\n","        avg_val_loss = total_eval_loss / len(validation_dataloader)\n","        \n","        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","\n","        # Record all statistics from this epoch.\n","        training_stats.append(\n","            {\n","                'epoch': epoch_i + 1,\n","                'Training Loss': avg_train_loss,\n","                'Valid. Loss': avg_val_loss,\n","            }\n","        )\n","    return model, training_stats"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fY0_L9G7gsWE"},"source":["ft_dnabert_model, training_stats = train(model, optimizer, scheduler, epochs, \n","              train_dataloader, validation_dataloader, device, clip_value=2)"],"execution_count":null,"outputs":[]}]}